{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "from src.models import rnn\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from typing import Callable, Optional\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "import gin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 13:16:40.373 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    def __init__(self, max: int, vocab: Vocab, clean: Optional[Callable]) -> None:\n",
    "        super().__init__(max, vocab, clean)\n",
    "\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "        return d[label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lenght = 50\n",
    "preprocessor = StylePreprocessor(max=max_lenght, vocab=v, clean=tokenizer.clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 48]),\n",
       " tensor([2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 0, 1, 1, 2, 0, 0, 1, 2, 3, 1, 1,\n",
       "         2, 2, 0, 0, 0, 1, 2, 2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "\n",
    "x, y = next(trainstreamer)\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 13:16:42.161501: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import trax\n",
    "\n",
    "def Cast():\n",
    "    \"Adding padding to sequences, as the trax model doesn't allow for different sequence lengths\"\n",
    "    def f(generator, max_len = max_lenght):\n",
    "        for x, y in generator:\n",
    "            new_x = []\n",
    "            _x = x.numpy()\n",
    "            for i in range(len(_x)):\n",
    "                array = _x[i]\n",
    "                new_x.append(np.pad(array, (0, max_len - len(array))))\n",
    "            yield np.array(new_x), y.numpy()\n",
    "    return lambda g: f(g)\n",
    "\n",
    "\n",
    "data_pipeline = trax.data.Serial(Cast())\n",
    "trainpipe = data_pipeline(trainstreamer)\n",
    "testpipe = data_pipeline(teststreamer)\n",
    "X, y = next(trainpipe)\n",
    "type(X), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.shapes import signature\n",
    "from src.models import rnnTrax\n",
    "\n",
    "gin.parse_config_file(\"model.gin\")\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "\n",
    "model = rnnTrax.NLPTraxCausalAttentionOneGruLast()\n",
    "\n",
    "model.init_weights_and_state(signature(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.supervised.lr_schedules import constant\n",
    "\n",
    "lr = constant(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.supervised.lr_schedules import warmup_and_rsqrt_decay\n",
    "\n",
    "lr = warmup_and_rsqrt_decay(100, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.supervised import training\n",
    "from trax import layers as tl\n",
    "from src.models import metrics\n",
    "\n",
    "def train_model(steps):\n",
    "    log_dir = settings.log_dir\n",
    "    log_dir = data_tools.dir_add_timestamp(log_dir)\n",
    "\n",
    "    train_task = training.TrainTask(\n",
    "        labeled_data=trainpipe,\n",
    "        loss_layer=tl.CategoryCrossEntropy(),\n",
    "        optimizer=trax.optimizers.Adam(),\n",
    "        lr_schedule=lr\n",
    "    )\n",
    "\n",
    "    eval_task = training.EvalTask(\n",
    "        labeled_data=testpipe, metrics=[tl.CategoryAccuracy(), tl.WeightedFScore(), tl.CategoryCrossEntropy()], n_eval_batches=25\n",
    "    )\n",
    "\n",
    "    loop = training.Loop(\n",
    "        model,\n",
    "        train_task,\n",
    "        eval_tasks=[eval_task],\n",
    "        output_dir=log_dir,\n",
    "    )\n",
    "    loop.run(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 13:18:32.957 | INFO     | src.data.data_tools:dir_add_timestamp:66 - Logging to ../tune/20220626-1318\n",
      "/home/mladmin/.cache/pypoetry/virtualenvs/exam-22-QTUf-Kx1-py3.9/lib/python3.9/site-packages/jax/_src/lib/xla_bridge.py:514: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n",
      "/home/mladmin/.cache/pypoetry/virtualenvs/exam-22-QTUf-Kx1-py3.9/lib/python3.9/site-packages/trax/layers/base.py:851: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
      "  with gzip.GzipFile(fileobj=f, compresslevel=compresslevel) as gzipf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 2636676\n",
      "Step      1: Ran 1 train steps in 6.62 secs\n",
      "Step      1: train CategoryCrossEntropy |  1.38352680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mladmin/.cache/pypoetry/virtualenvs/exam-22-QTUf-Kx1-py3.9/lib/python3.9/site-packages/trax/supervised/training.py:1249: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
      "  with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step      1: eval      CategoryAccuracy |  0.31625000\n",
      "Step      1: eval        WeightedFScore |  0.15845168\n",
      "Step      1: eval  CategoryCrossEntropy |  1.38357815\n",
      "\n",
      "Step    100: Ran 99 train steps in 8.67 secs\n",
      "Step    100: train CategoryCrossEntropy |  1.06037641\n",
      "Step    100: eval      CategoryAccuracy |  0.80375000\n",
      "Step    100: eval        WeightedFScore |  0.78675003\n",
      "Step    100: eval  CategoryCrossEntropy |  0.57789233\n",
      "\n",
      "Step    200: Ran 100 train steps in 9.20 secs\n",
      "Step    200: train CategoryCrossEntropy |  0.44918513\n",
      "Step    200: eval      CategoryAccuracy |  0.86875000\n",
      "Step    200: eval        WeightedFScore |  0.84766730\n",
      "Step    200: eval  CategoryCrossEntropy |  0.34646960\n",
      "\n",
      "Step    300: Ran 100 train steps in 8.36 secs\n",
      "Step    300: train CategoryCrossEntropy |  0.31935063\n",
      "Step    300: eval      CategoryAccuracy |  0.90125000\n",
      "Step    300: eval        WeightedFScore |  0.90178746\n",
      "Step    300: eval  CategoryCrossEntropy |  0.29950951\n",
      "\n",
      "Step    400: Ran 100 train steps in 8.19 secs\n",
      "Step    400: train CategoryCrossEntropy |  0.22988319\n",
      "Step    400: eval      CategoryAccuracy |  0.89625000\n",
      "Step    400: eval        WeightedFScore |  0.89915290\n",
      "Step    400: eval  CategoryCrossEntropy |  0.29350025\n",
      "\n",
      "Step    500: Ran 100 train steps in 8.57 secs\n",
      "Step    500: train CategoryCrossEntropy |  0.16386200\n",
      "Step    500: eval      CategoryAccuracy |  0.91750000\n",
      "Step    500: eval        WeightedFScore |  0.91474520\n",
      "Step    500: eval  CategoryCrossEntropy |  0.25194691\n",
      "\n",
      "Step    600: Ran 100 train steps in 8.79 secs\n",
      "Step    600: train CategoryCrossEntropy |  0.16008715\n",
      "Step    600: eval      CategoryAccuracy |  0.90250000\n",
      "Step    600: eval        WeightedFScore |  0.90588288\n",
      "Step    600: eval  CategoryCrossEntropy |  0.25438596\n",
      "\n",
      "Step    700: Ran 100 train steps in 8.39 secs\n",
      "Step    700: train CategoryCrossEntropy |  0.14010680\n",
      "Step    700: eval      CategoryAccuracy |  0.92625000\n",
      "Step    700: eval        WeightedFScore |  0.92903203\n",
      "Step    700: eval  CategoryCrossEntropy |  0.20693217\n",
      "\n",
      "Step    800: Ran 100 train steps in 8.44 secs\n",
      "Step    800: train CategoryCrossEntropy |  0.09717610\n",
      "Step    800: eval      CategoryAccuracy |  0.92750000\n",
      "Step    800: eval        WeightedFScore |  0.92800030\n",
      "Step    800: eval  CategoryCrossEntropy |  0.26749270\n",
      "\n",
      "Step    900: Ran 100 train steps in 8.40 secs\n",
      "Step    900: train CategoryCrossEntropy |  0.03521704\n",
      "Step    900: eval      CategoryAccuracy |  0.91125000\n",
      "Step    900: eval        WeightedFScore |  0.91748475\n",
      "Step    900: eval  CategoryCrossEntropy |  0.33666193\n",
      "\n",
      "Step   1000: Ran 100 train steps in 8.33 secs\n",
      "Step   1000: train CategoryCrossEntropy |  0.04770902\n",
      "Step   1000: eval      CategoryAccuracy |  0.93750000\n",
      "Step   1000: eval        WeightedFScore |  0.93749955\n",
      "Step   1000: eval  CategoryCrossEntropy |  0.22968166\n",
      "\n",
      "Step   1100: Ran 100 train steps in 8.34 secs\n",
      "Step   1100: train CategoryCrossEntropy |  0.05083050\n",
      "Step   1100: eval      CategoryAccuracy |  0.92625000\n",
      "Step   1100: eval        WeightedFScore |  0.92711704\n",
      "Step   1100: eval  CategoryCrossEntropy |  0.29380579\n",
      "\n",
      "Step   1200: Ran 100 train steps in 8.31 secs\n",
      "Step   1200: train CategoryCrossEntropy |  0.03732378\n",
      "Step   1200: eval      CategoryAccuracy |  0.90375000\n",
      "Step   1200: eval        WeightedFScore |  0.91014370\n",
      "Step   1200: eval  CategoryCrossEntropy |  0.30024546\n",
      "\n",
      "Step   1300: Ran 100 train steps in 8.27 secs\n",
      "Step   1300: train CategoryCrossEntropy |  0.01421129\n",
      "Step   1300: eval      CategoryAccuracy |  0.92375000\n",
      "Step   1300: eval        WeightedFScore |  0.92391368\n",
      "Step   1300: eval  CategoryCrossEntropy |  0.32927301\n",
      "\n",
      "Step   1400: Ran 100 train steps in 8.21 secs\n",
      "Step   1400: train CategoryCrossEntropy |  0.02177538\n",
      "Step   1400: eval      CategoryAccuracy |  0.91375000\n",
      "Step   1400: eval        WeightedFScore |  0.91182195\n",
      "Step   1400: eval  CategoryCrossEntropy |  0.44292358\n",
      "\n",
      "Step   1500: Ran 100 train steps in 8.13 secs\n",
      "Step   1500: train CategoryCrossEntropy |  0.01083477\n",
      "Step   1500: eval      CategoryAccuracy |  0.92625000\n",
      "Step   1500: eval        WeightedFScore |  0.92632919\n",
      "Step   1500: eval  CategoryCrossEntropy |  0.39249576\n",
      "\n",
      "Step   1600: Ran 100 train steps in 8.44 secs\n",
      "Step   1600: train CategoryCrossEntropy |  0.01460257\n",
      "Step   1600: eval      CategoryAccuracy |  0.91625000\n",
      "Step   1600: eval        WeightedFScore |  0.91762590\n",
      "Step   1600: eval  CategoryCrossEntropy |  0.39245729\n",
      "\n",
      "Step   1700: Ran 100 train steps in 8.34 secs\n",
      "Step   1700: train CategoryCrossEntropy |  0.01095157\n",
      "Step   1700: eval      CategoryAccuracy |  0.93125000\n",
      "Step   1700: eval        WeightedFScore |  0.93360027\n",
      "Step   1700: eval  CategoryCrossEntropy |  0.25371170\n",
      "\n",
      "Step   1800: Ran 100 train steps in 8.38 secs\n",
      "Step   1800: train CategoryCrossEntropy |  0.00896295\n",
      "Step   1800: eval      CategoryAccuracy |  0.92250000\n",
      "Step   1800: eval        WeightedFScore |  0.92340232\n",
      "Step   1800: eval  CategoryCrossEntropy |  0.36996624\n",
      "\n",
      "Step   1900: Ran 100 train steps in 8.31 secs\n",
      "Step   1900: train CategoryCrossEntropy |  0.00680576\n",
      "Step   1900: eval      CategoryAccuracy |  0.91875000\n",
      "Step   1900: eval        WeightedFScore |  0.91877037\n",
      "Step   1900: eval  CategoryCrossEntropy |  0.38483186\n",
      "\n",
      "Step   2000: Ran 100 train steps in 8.31 secs\n",
      "Step   2000: train CategoryCrossEntropy |  0.00627553\n",
      "Step   2000: eval      CategoryAccuracy |  0.92125000\n",
      "Step   2000: eval        WeightedFScore |  0.92017645\n",
      "Step   2000: eval  CategoryCrossEntropy |  0.42417757\n",
      "\n",
      "Step   2100: Ran 100 train steps in 8.37 secs\n",
      "Step   2100: train CategoryCrossEntropy |  0.00129187\n",
      "Step   2100: eval      CategoryAccuracy |  0.92250000\n",
      "Step   2100: eval        WeightedFScore |  0.92461641\n",
      "Step   2100: eval  CategoryCrossEntropy |  0.52723603\n",
      "\n",
      "Step   2200: Ran 100 train steps in 8.30 secs\n",
      "Step   2200: train CategoryCrossEntropy |  0.00518361\n",
      "Step   2200: eval      CategoryAccuracy |  0.91125000\n",
      "Step   2200: eval        WeightedFScore |  0.91302659\n",
      "Step   2200: eval  CategoryCrossEntropy |  0.44956435\n",
      "\n",
      "Step   2300: Ran 100 train steps in 8.43 secs\n",
      "Step   2300: train CategoryCrossEntropy |  0.00821749\n",
      "Step   2300: eval      CategoryAccuracy |  0.93375000\n",
      "Step   2300: eval        WeightedFScore |  0.93893643\n",
      "Step   2300: eval  CategoryCrossEntropy |  0.28940245\n",
      "\n",
      "Step   2400: Ran 100 train steps in 8.16 secs\n",
      "Step   2400: train CategoryCrossEntropy |  0.01452581\n",
      "Step   2400: eval      CategoryAccuracy |  0.91875000\n",
      "Step   2400: eval        WeightedFScore |  0.92290801\n",
      "Step   2400: eval  CategoryCrossEntropy |  0.38061940\n",
      "\n",
      "Step   2500: Ran 100 train steps in 8.06 secs\n",
      "Step   2500: train CategoryCrossEntropy |  0.00332572\n",
      "Step   2500: eval      CategoryAccuracy |  0.91375000\n",
      "Step   2500: eval        WeightedFScore |  0.91291024\n",
      "Step   2500: eval  CategoryCrossEntropy |  0.59051613\n",
      "\n",
      "Step   2600: Ran 100 train steps in 8.76 secs\n",
      "Step   2600: train CategoryCrossEntropy |  0.01322383\n",
      "Step   2600: eval      CategoryAccuracy |  0.90875000\n",
      "Step   2600: eval        WeightedFScore |  0.91161872\n",
      "Step   2600: eval  CategoryCrossEntropy |  0.41386941\n",
      "\n",
      "Step   2700: Ran 100 train steps in 8.23 secs\n",
      "Step   2700: train CategoryCrossEntropy |  0.00707580\n",
      "Step   2700: eval      CategoryAccuracy |  0.90250000\n",
      "Step   2700: eval        WeightedFScore |  0.90656157\n",
      "Step   2700: eval  CategoryCrossEntropy |  0.69715344\n",
      "\n",
      "Step   2800: Ran 100 train steps in 8.25 secs\n",
      "Step   2800: train CategoryCrossEntropy |  0.00804572\n",
      "Step   2800: eval      CategoryAccuracy |  0.93500000\n",
      "Step   2800: eval        WeightedFScore |  0.93964474\n",
      "Step   2800: eval  CategoryCrossEntropy |  0.33995440\n",
      "\n",
      "Step   2900: Ran 100 train steps in 8.27 secs\n",
      "Step   2900: train CategoryCrossEntropy |  0.00294637\n",
      "Step   2900: eval      CategoryAccuracy |  0.89875000\n",
      "Step   2900: eval        WeightedFScore |  0.90058438\n",
      "Step   2900: eval  CategoryCrossEntropy |  0.75134793\n",
      "\n",
      "Step   3000: Ran 100 train steps in 8.37 secs\n",
      "Step   3000: train CategoryCrossEntropy |  0.00098694\n",
      "Step   3000: eval      CategoryAccuracy |  0.92375000\n",
      "Step   3000: eval        WeightedFScore |  0.92851650\n",
      "Step   3000: eval  CategoryCrossEntropy |  0.44995298\n"
     ]
    }
   ],
   "source": [
    "train_model(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEVINDINGEN\n",
    "\n",
    "In trax heb ik eerst een base model gemaakt, met een embedding laag, GRU laag, dropout laag, hier nemen we vervolgens de laatste hidden state van, die wordt gevoed aan de dense laag (zie rnnTrax - BaseNLPTrax). De geselecteerde trax metrics zijn categorical accuracy en WeightedFScore. Dit model, met één GRU laag haalt na 3000 trainingsstappen een weightedFScore behaald van 89%, dat is beter dan het Pytorch model met 2 of 3 lagen! In de tensorboard afbeeldingen is te zien dat het model eerst door alle trainingsvoorbeelden gaat, hier blijft loss/accuraatheid nog horizontaal. Vervolgens, na 1500 stappen begint het model te leren, de loss neemt af en F score neemt snel toe. \n",
    "\n",
    "Vervolgens is het model aangepast naar 2 GRU lagen, beide opgevolgd door een Dropout laag. Dit model begint pas veel later te leren (na 5000 trainingsstappen). Het model bereikt gelijke accuraatheid als het model met één GRU laag. \n",
    "\n",
    "In plaats van het nemen van de laatste hidden state van de GRU, kunnen we ook het gemiddelde van de hidden states nemen. Wanneer dit model gerunt wordt, traint het model gelijk vanaf de eerste stap. Dit model met één laag bereikt na 3000 stappen een fscore van 85%. Hetzelfde model met 2 GRU lagen bereikt een Fscore van 87%. Dit is dus al beter, maar nog steeds minder goed als het toepassen van de \"Last\" layer. Ook de test loss van het model met de AvgLast layer blijft iets achter bij de test loss van het model met Last layer. Bij de afweging tussen deze twee modellen is ook de prioritering trainingstijd vs accuraatheid belangrijk.\n",
    "\n",
    "Vervolgens wordt het aantal units vergroot van 128 naar 256. Dit model bereikt erg snel een hoge accuraatheid, maar accuraatheid neemt na 1000 stappen (84%) bijna niet meer toe (model eindigd op 86%). Het model overtraint wel.\n",
    "\n",
    "Voor bovenstaande modellen wordt nog een constante learning rate gebruikt. Nu willen we een variabele learning rate toepassen. Een mogelijkheid hiertoe is het gebruiken van de warm-up decay scheduler. Hieronder is te zien hoe het schema van deze scheduler er uit ziet. Het model begint met een lage learning rate, deze neemt vervolgens heel snel toe en neemt dan langzaam af. Het model wordt gerunt met 3000 trainingsstappen, en outperformed alle voorgaande modellen. Een Fscore van 90% wordt behaald. Wel overtraind het model opnieuw, te zien aan de toenemende test loss en nog steeds afnemende train loss.\n",
    "\n",
    "Wellicht zou het toevoegen van een attention layer nog wat extra intelligentie toevoegen aan het model. Dit model is genoemd \"NLPTraxCausalAttention\". Er is een CausalAttention layer toegevoegd. De causal attention laag is een variatie op de normale Attention layer welke tracht de bias van de normale attention layer naar onterechte correlaties in de training data weg te halen. Deze bias zorgt in de normale attention layer voor minder generaliseerbaarheid van het model. Het toevoegen van de attention layer heeft een klein positief effect op de Fscore (91%).\n",
    "\n",
    "Vervolgens heb ik de 2e GRU layer uit het model gehaald, omdat het model \"NLPTraxCausalAttention\" aan het overtrainen was (te zien aan de test loss). Wellicht is het model te complex. Dit lijkt inderdaad te werken, de loss wordt sneller kleiner, maar dit model moet niet te lang doorgetraind worden omdat het dan wel weer gaat overtrainen (1500 stappen is voldoende). Dit zorgde ook voor een verbetering van de Fscore naar 92%.\n",
    "\n",
    "Als laatste test nog de avglast() layer aangepast naar de last() layer. In de architectuur met 1 GRU en een Causal attention layer komt deze beter tot zijn recht. De Fscore verbeterd weer iets (93%), en ook neemt de loss sneller af."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f96b07246a0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trax.supervised.lr_schedules import warmup_and_rsqrt_decay\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"dark_background\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "lr = warmup_and_rsqrt_decay(100, 0.01)\n",
    "steps = jnp.arange(3000)\n",
    "y = [lr(x) for x in steps]\n",
    "plt.plot(steps, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-QTUf-Kx1-py3.9': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6e807b2bb5ac5eb176c4c6775a07937f8bceddd7fa23b8060fe36db016dbd75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
