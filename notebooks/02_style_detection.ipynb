{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "from src.models import rnn\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from typing import Callable, Optional\n",
    "from torchtext.vocab import Vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testdataset) //32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419.09375"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset)/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "104+419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 16:35:57.682 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Figure out, for every class, what accuracy you should expect if the model would guess blind on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humor: 0.31414510476474533\n",
      "wiki: 0.31175900380284843\n",
      "proverbs: 0.06196405935426143\n",
      "reuters: 0.3121318320781448\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "dataset = traindataset\n",
    "list_labels = []\n",
    "for i in range(len(dataset)):\n",
    "    label = dataset[i][1]\n",
    "    list_labels.append(label)\n",
    "\n",
    "counter = Counter(list_labels)\n",
    "\n",
    "for i in counter:\n",
    "    percent_observations = counter[i]/len(dataset)\n",
    "    print(\"{}: {}\".format(i, percent_observations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you see. What does this mean? What implications does this have? Why is that good/bad?\n",
    "Are there things down the line that could cause a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER\n",
    "\n",
    "1. What does this mean?\n",
    "\n",
    "There are 4 categories, of which 3 have about the same number of observations, but the 4th one has significantly less observations. Therefore, the traindataset is unbalanced, where the class (proverbs) has less observations.\n",
    "\n",
    "2. What implications does this have?\n",
    "\n",
    "A different metric/loss function is necessary to measure accuracy.\n",
    "\n",
    "3. Why is this good/bad?\n",
    "\n",
    "The model will have a hard time to learn to classify proverbs, it will be biased towards the majority classes.\n",
    "\n",
    "4. Things that could cause a problem down the line:\n",
    "\n",
    "This dataset is not a balanced one, the category proverbs has significantly less observations available. The amount of observations in this class make up 6% of observations while the others all make up for around 31% of observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    def __init__(self, max: int, vocab: Vocab, clean: Optional[Callable]) -> None:\n",
    "        super().__init__(max, vocab, clean)\n",
    "\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "        return d[label]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4929,  854,   32,   15,  499,   21, 8496,  890]], dtype=torch.int32),\n",
       " tensor([2]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "preprocessor([(x, y)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 34]),\n",
       " tensor([2, 0, 2, 1, 0, 2, 0, 1, 0, 2, 3, 2, 0, 0, 2, 1, 2, 1, 1, 1, 0, 1, 2, 1,\n",
       "         1, 0, 1, 0, 0, 0, 1, 2]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.data.data_tools.StyleDataset at 0x7f24542dd250>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : Metrics, loss\n",
    "Select proper metrics and a loss function.\n",
    "\n",
    "Bonus: implement an additional metric function that is relevant for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "# F1 score metric is good for unbalanced datasets (which we have), this measure combines precision and recall. \n",
    "# Accuracy metric is also loaded to compare with F1 Score\n",
    "metrics = [metrics.F1Score(), metrics.Accuracy()]\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : Basemodel\n",
    "Create a base model. It does not need to be naive; you could re-use the\n",
    "NLP models we used for the IMDB.\n",
    "\n",
    "I suggest to start with a hidden size of about 128.\n",
    "Use a config dictionary, or a gin file, both are fine.\n",
    "\n",
    "Bonus points if you create a Trax model in src.models, and even more if you add a trax training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE -> TRAX\n",
    "\n",
    "For the trax implementation, see src.models.rnnTrax\n",
    "For the notebook (inc trainloop) running this model, see the notebook 02_StyleDetectionTrax.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "log_dir = settings.log_dir\n",
    "# TODO between 2 and 8 lines of code, depending on your setup\n",
    "# Assuming you load your model in one line of code from src.models.rnn\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "\n",
    "model = rnn.NLPmodel(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainloop.\n",
    "\n",
    "- Give the lenght of the traindataset, how many batches of 32 can you get out of it?\n",
    "\n",
    "419\n",
    "\n",
    "- If you take a short amount of train_steps (eg 25) for every epoch, how many epochs do you need to cover the complete dataset?\n",
    "\n",
    "There are 103 batches in testset, so 523 in entire dataset.\n",
    "523/25 = 20.92 = 21\n",
    "\n",
    "- What amount of epochs do you need to run the loop with trainsteps=25 to cover the complete traindataset once? \n",
    "\n",
    "419/25 = 16.76 = 17\n",
    "\n",
    "- answer the questions above, and pick a reasonable epoch lenght\n",
    "\n",
    "Picked 20 epochs\n",
    "\n",
    "\n",
    "Start with a default learning_rate of 1e-3 and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 16:36:01.438189: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-28 16:36:01.438227: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-28 16:36:03.492 | INFO     | src.data.data_tools:dir_add_timestamp:65 - Logging to ../tune/20220628-1636\n",
      "100%|██████████| 25/25 [00:11<00:00,  2.20it/s]\n",
      "2022-06-28 16:36:15.787 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 1.2916 test 1.2702 metric ['0.1669', '0.3312']\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.87it/s]\n",
      "2022-06-28 16:36:18.019 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 1.2308 test 1.2980 metric ['0.2845', '0.4213']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.74it/s]\n",
      "2022-06-28 16:36:20.237 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 1.1806 test 1.0570 metric ['0.3773', '0.5238']\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.74it/s]\n",
      "2022-06-28 16:36:22.518 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 1.0634 test 0.9198 metric ['0.3589', '0.5425']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.72it/s]\n",
      "2022-06-28 16:36:24.662 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.8806 test 0.7253 metric ['0.5842', '0.7375']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.14it/s]\n",
      "2022-06-28 16:36:26.646 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.7420 test 0.5883 metric ['0.6347', '0.7950']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.75it/s]\n",
      "2022-06-28 16:36:28.695 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.6389 test 0.5531 metric ['0.6551', '0.8037']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.74it/s]\n",
      "2022-06-28 16:36:30.690 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.5856 test 0.5475 metric ['0.6639', '0.8037']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.15it/s]\n",
      "2022-06-28 16:36:32.679 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.5901 test 0.5509 metric ['0.6494', '0.7850']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.19it/s]\n",
      "2022-06-28 16:36:34.767 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.5528 test 0.4634 metric ['0.7034', '0.8225']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.98it/s]\n",
      "2022-06-28 16:36:36.895 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.4692 test 0.4761 metric ['0.7221', '0.8287']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.25it/s]\n",
      "2022-06-28 16:36:38.986 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.4857 test 0.4658 metric ['0.7125', '0.8300']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.20it/s]\n",
      "2022-06-28 16:36:40.895 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.4111 test 0.4257 metric ['0.7669', '0.8425']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.01it/s]\n",
      "2022-06-28 16:36:43.002 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.4346 test 0.4235 metric ['0.7390', '0.8562']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.14it/s]\n",
      "2022-06-28 16:36:45.022 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.4211 test 0.3837 metric ['0.7416', '0.8750']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.17it/s]\n",
      "2022-06-28 16:36:46.973 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.4138 test 0.3870 metric ['0.7661', '0.8688']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.42it/s]\n",
      "2022-06-28 16:36:49.077 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.4256 test 0.3933 metric ['0.8007', '0.8725']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.63it/s]\n",
      "2022-06-28 16:36:51.191 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.3072 test 0.3917 metric ['0.7698', '0.8675']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.97it/s]\n",
      "2022-06-28 16:36:53.292 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.3289 test 0.3843 metric ['0.7531', '0.8538']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.93it/s]\n",
      "2022-06-28 16:36:55.208 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.3455 test 0.3970 metric ['0.7798', '0.8612']\n",
      "100%|██████████| 20/20 [00:51<00:00,  2.59s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=20,\n",
    "    model=model,\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image from the training in tensorboard in the `figures` folder.\n",
    "Explain what you are seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER\n",
    "\n",
    "After 20 epochs, the model is still learning, in both the test and train loss we can see that loss is still decreasing. For further tuning, the amount of epochs should increase. The model is learning more slowly than at the start though, perhaps we can implement step-wise decrease of the learning rate to keep speedy learning at the beginning and change to a lower learning rate once the learning slows down. \n",
    "\n",
    "There are two metrics taken into account, the f1 score and accuracy. We should look mostly at the F1-score as this metric is better adapted to unbalanced datasets. It is visible that accuracy score is indeed significantly higher. F1-score is up to around 75% after 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate the basemodel\n",
    "Create a confusion matrix with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 15.0, 'Predicted'), Text(33.0, 0.5, 'Target')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this in the figures folder. -> figure saved as \"confusionMatrix.png\"\n",
    "\n",
    "Interpret this. \n",
    "\n",
    "- What is going on?\n",
    "\n",
    "The model performs relatively good for categories 0, 1, and 2, but underperforms significantly for category 3. This is because the model has a bias towards the first 3 categories, as they have many more observations. Most of the wrongly categorized items from category 3 (proverbs) are classified as 2 (wiki).\n",
    "\n",
    "- What is a good metric here?\n",
    "\n",
    "F1 score (precision/recall)\n",
    "\n",
    "- how is your answer to Q1 relevant here?\n",
    "\n",
    "Very, without having the knowledge of the dataset being unbalanced, it wouldn't have been clear why category 3 underperforms so much.\n",
    "\n",
    "- Is there something you could do to fix/improve things, after you see these results?\n",
    "\n",
    "Make the dataset balanced by oversampling the 3rd category or undersampling the first three categories. I would go for oversampling the 3rd (containing less observations) category, because otherwise many observations will be lost. Another way to deal with this is selecting a model (architecture) that deals well with unbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPERIMENTS\n",
    "\n",
    "1. Experiment one - Attention layer\n",
    "\n",
    "Added an attention layer (AttentionNPL in src.models). This is basically the same model as NLPModel but with the addition of an attention layer. In the loss figures, it is visible that this model learns faster than the NLPModel. After 20 epochs, the f1 score of this model is 80% (whereas the base model got to 78% after 20 epochs). \n",
    "\n",
    "2. Experiment two - Add learning rate scheduler\n",
    "\n",
    "Added a learning rate scheduler to the trainloop that starts with LR of 1e-3 and decreases the learning rate with factor of 0.9 if the model doesn't learn for 3 epochs. For this experiment, the number of epochs is also increased, as the model needs more time to plateau. The number of epochs is now set to 100. This model has an f1 score of 86% after 20 epochs. Learning rate has decreased from 1e-3 to 1.35e-4. The negative side of this model is that we see the test loss starting to increase after 60 epochs, this implies overtraining. In order to have less overtraining, we have to make the model a bit more simple, so that the model doesn't completely adapt to the training data. Therefore we now use only 2 GRU layers (instead of 3) with a dropout of 0.2 (instead of 0.1). This seems to work. The model has the same f1 score after 100 epochs, but test loss increases significanly less. \n",
    "\n",
    "3. Experiment three - Adjust for class imbalance\n",
    "As we have unbalanced data, we can use the parameter \"weights\" of CrossEntropyLoss in oder to adjust for this class imbalance. In order to do this, we need to calculated the weights for each class. This is calculated by [total number of observations] / [number of observations] and make this calculation per class. In the cell below the weights are calculated. When I compare two models that are completely the same, except for the fact that one model has the crossentropyloss function with weights and the other has no weights of classes, the f1 score increases by 3% (see figure \"F1ScoreWeighted\", where the green line is the model with weighted loss). The results are better visible in the confustion matrix, see figure \"confusionmatrixweighted.png\". \n",
    " \n",
    "\n",
    "FOR FURTHER EXPERIMENTATION - SEE TRAX NOTEBOOK (02_style_detection_trax.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7958, 0.8009, 0.8019, 4.0346])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import utils\n",
    "\n",
    "def cast_label(label: str) -> int:\n",
    "        d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "        return d[label]\n",
    "\n",
    "intlabels = [cast_label(i) for i in list_labels]\n",
    "weights = utils.class_weight.compute_class_weight(\"balanced\", classes = np.unique(intlabels), y= np.array(intlabels))\n",
    "weights = torch.tensor(weights, dtype=torch.float)\n",
    "print(weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 15:17:59.467 | INFO     | src.data.data_tools:dir_add_timestamp:66 - Logging to ../tune/20220625-1517\n",
      "100%|██████████| 25/25 [00:04<00:00,  5.88it/s]\n",
      "2022-06-25 15:18:04.703 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 1.2686 test 1.1356 metric ['0.3617', '0.4675']\n",
      "100%|██████████| 25/25 [00:04<00:00,  6.03it/s]\n",
      "2022-06-25 15:18:09.550 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 1.1025 test 0.9567 metric ['0.3939', '0.5413']\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.06it/s]\n",
      "2022-06-25 15:18:12.281 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 0.9200 test 0.8157 metric ['0.5298', '0.6950']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.71it/s]\n",
      "2022-06-25 15:18:14.481 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 0.7423 test 0.6713 metric ['0.6368', '0.7600']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.80it/s]\n",
      "2022-06-25 15:18:16.631 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.6166 test 0.5576 metric ['0.6804', '0.7900']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.31it/s]\n",
      "2022-06-25 15:18:18.770 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.5495 test 0.5369 metric ['0.7100', '0.7925']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.53it/s]\n",
      "2022-06-25 15:18:20.847 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.5043 test 0.4782 metric ['0.7410', '0.8400']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.42it/s]\n",
      "2022-06-25 15:18:22.937 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.4757 test 0.4085 metric ['0.7957', '0.8662']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.10it/s]\n",
      "2022-06-25 15:18:25.043 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.4492 test 0.4587 metric ['0.7579', '0.8413']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.11it/s]\n",
      "2022-06-25 15:18:27.075 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.4440 test 0.4492 metric ['0.7688', '0.8375']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.75it/s]\n",
      "2022-06-25 15:18:29.257 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.4182 test 0.3998 metric ['0.7684', '0.8625']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.87it/s]\n",
      "2022-06-25 15:18:31.399 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.3617 test 0.3999 metric ['0.8042', '0.8525']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.38it/s]\n",
      "2022-06-25 15:18:33.379 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.3730 test 0.3567 metric ['0.7821', '0.8700']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.72it/s]\n",
      "2022-06-25 15:18:35.527 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.3858 test 0.3873 metric ['0.7649', '0.8612']\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.69it/s]\n",
      "2022-06-25 15:18:37.848 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.3644 test 0.3644 metric ['0.8162', '0.8800']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.60it/s]\n",
      "2022-06-25 15:18:39.920 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.4307 test 0.4050 metric ['0.7638', '0.8575']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.51it/s]\n",
      "2022-06-25 15:18:41.975 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.3027 test 0.3394 metric ['0.8184', '0.8925']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.30it/s]\n",
      "2022-06-25 15:18:44.204 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.3051 test 0.3499 metric ['0.8029', '0.8662']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.25it/s]\n",
      "2022-06-25 15:18:46.432 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.3115 test 0.3279 metric ['0.8311', '0.8875']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.18it/s]\n",
      "2022-06-25 15:18:48.468 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.3172 test 0.3793 metric ['0.7812', '0.8688']\n",
      "100%|██████████| 20/20 [00:48<00:00,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=20,\n",
    "    model=rnn.AttentionNLP(config),\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 16:48:27.842 | INFO     | src.data.data_tools:dir_add_timestamp:65 - Logging to ../tune/20220628-1648\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.66it/s]\n",
      "2022-06-28 16:48:42.474 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 1.2191 test 0.9724 metric ['0.5860', '0.6525']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.34it/s]\n",
      "2022-06-28 16:48:47.225 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 0.8469 test 0.7706 metric ['0.5946', '0.6706']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.51it/s]\n",
      "2022-06-28 16:48:51.861 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 0.6983 test 0.6856 metric ['0.6990', '0.7788']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.78it/s]\n",
      "2022-06-28 16:48:56.266 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 0.5872 test 0.6205 metric ['0.6875', '0.7569']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.06it/s]\n",
      "2022-06-28 16:49:00.896 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.5324 test 0.5465 metric ['0.7270', '0.8025']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.95it/s]\n",
      "2022-06-28 16:49:05.581 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.5366 test 0.5497 metric ['0.7614', '0.8419']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.76it/s]\n",
      "2022-06-28 16:49:10.286 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.5414 test 0.5796 metric ['0.7210', '0.7706']\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.01it/s]\n",
      "2022-06-28 16:49:14.661 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.3604 test 0.5085 metric ['0.7354', '0.8144']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.25it/s]\n",
      "2022-06-28 16:49:19.170 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.3496 test 0.4748 metric ['0.7774', '0.8425']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.20it/s]\n",
      "2022-06-28 16:49:23.703 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.4040 test 0.4454 metric ['0.7706', '0.8319']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.29it/s]\n",
      "2022-06-28 16:49:28.196 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.3599 test 0.6153 metric ['0.7384', '0.8137']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.83it/s]\n",
      "2022-06-28 16:49:32.516 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.3506 test 0.4796 metric ['0.7712', '0.8306']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.95it/s]\n",
      "2022-06-28 16:49:37.086 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.3425 test 0.6554 metric ['0.6889', '0.7719']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.74it/s]\n",
      "2022-06-28 16:49:41.455 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.3427 test 0.4652 metric ['0.7463', '0.8313']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.59it/s]\n",
      "2022-06-28 16:49:46.079 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.3497 test 0.4391 metric ['0.7528', '0.8169']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.83it/s]\n",
      "2022-06-28 16:49:50.864 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.2637 test 0.5984 metric ['0.7977', '0.8619']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.54it/s]\n",
      "2022-06-28 16:49:55.479 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.2105 test 0.3922 metric ['0.8411', '0.8850']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.68it/s]\n",
      "2022-06-28 16:50:00.455 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.2271 test 0.4312 metric ['0.7764', '0.8431']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.36it/s]\n",
      "2022-06-28 16:50:05.206 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.1963 test 0.4825 metric ['0.7989', '0.8588']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.01it/s]\n",
      "2022-06-28 16:50:10.151 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.2169 test 0.5024 metric ['0.8177', '0.8819']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.80it/s]\n",
      "2022-06-28 16:50:14.799 | INFO     | src.training.train_model:trainloop:164 - Epoch 20 train 0.1866 test 0.4572 metric ['0.8210', '0.8775']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.76it/s]\n",
      "2022-06-28 16:50:19.241 | INFO     | src.training.train_model:trainloop:164 - Epoch 21 train 0.2229 test 0.3553 metric ['0.8257', '0.8831']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.70it/s]\n",
      "2022-06-28 16:50:23.865 | INFO     | src.training.train_model:trainloop:164 - Epoch 22 train 0.1964 test 0.4393 metric ['0.7922', '0.8475']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.09it/s]\n",
      "2022-06-28 16:50:28.481 | INFO     | src.training.train_model:trainloop:164 - Epoch 23 train 0.1925 test 0.4337 metric ['0.8087', '0.8675']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.13it/s]\n",
      "2022-06-28 16:50:33.023 | INFO     | src.training.train_model:trainloop:164 - Epoch 24 train 0.1158 test 0.4638 metric ['0.8121', '0.8744']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.50it/s]\n",
      "2022-06-28 16:50:37.451 | INFO     | src.training.train_model:trainloop:164 - Epoch 25 train 0.1346 test 0.4943 metric ['0.8203', '0.8812']\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.01it/s]\n",
      "2022-06-28 16:50:41.801 | INFO     | src.training.train_model:trainloop:164 - Epoch 26 train 0.1259 test 0.4269 metric ['0.8409', '0.8856']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.40it/s]\n",
      "2022-06-28 16:50:46.318 | INFO     | src.training.train_model:trainloop:164 - Epoch 27 train 0.1618 test 0.4633 metric ['0.8023', '0.8581']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.88it/s]\n",
      "2022-06-28 16:50:50.931 | INFO     | src.training.train_model:trainloop:164 - Epoch 28 train 0.1149 test 0.4306 metric ['0.8494', '0.8956']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.01it/s]\n",
      "2022-06-28 16:50:55.647 | INFO     | src.training.train_model:trainloop:164 - Epoch 29 train 0.1136 test 0.4956 metric ['0.8114', '0.8725']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.79it/s]\n",
      "2022-06-28 16:51:00.240 | INFO     | src.training.train_model:trainloop:164 - Epoch 30 train 0.1240 test 0.4549 metric ['0.8291', '0.8944']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.04it/s]\n",
      "2022-06-28 16:51:04.815 | INFO     | src.training.train_model:trainloop:164 - Epoch 31 train 0.1036 test 0.3749 metric ['0.8466', '0.8988']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.87it/s]\n",
      "2022-06-28 16:51:09.143 | INFO     | src.training.train_model:trainloop:164 - Epoch 32 train 0.0728 test 0.5123 metric ['0.8476', '0.8938']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.45it/s]\n",
      "2022-06-28 16:51:13.621 | INFO     | src.training.train_model:trainloop:164 - Epoch 33 train 0.0695 test 0.6201 metric ['0.8334', '0.8944']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.79it/s]\n",
      "2022-06-28 16:51:18.266 | INFO     | src.training.train_model:trainloop:164 - Epoch 34 train 0.0792 test 0.5534 metric ['0.8367', '0.8956']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.25it/s]\n",
      "2022-06-28 16:51:22.742 | INFO     | src.training.train_model:trainloop:164 - Epoch 35 train 0.0613 test 0.6821 metric ['0.8436', '0.8906']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.67it/s]\n",
      "2022-06-28 16:51:27.402 | INFO     | src.training.train_model:trainloop:164 - Epoch 36 train 0.0804 test 0.4958 metric ['0.8380', '0.8812']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.29it/s]\n",
      "2022-06-28 16:51:31.884 | INFO     | src.training.train_model:trainloop:164 - Epoch 37 train 0.0593 test 0.7074 metric ['0.8205', '0.8750']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.72it/s]\n",
      "2022-06-28 16:51:36.254 | INFO     | src.training.train_model:trainloop:164 - Epoch 38 train 0.0861 test 0.5933 metric ['0.8193', '0.8825']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.76it/s]\n",
      "2022-06-28 16:51:40.629 | INFO     | src.training.train_model:trainloop:164 - Epoch 39 train 0.0672 test 0.5293 metric ['0.8241', '0.8956']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.23it/s]\n",
      "2022-06-28 16:51:45.141 | INFO     | src.training.train_model:trainloop:164 - Epoch 40 train 0.0567 test 0.4972 metric ['0.8527', '0.8969']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.02it/s]\n",
      "2022-06-28 16:51:49.789 | INFO     | src.training.train_model:trainloop:164 - Epoch 41 train 0.0495 test 0.5631 metric ['0.8398', '0.8888']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.01it/s]\n",
      "2022-06-28 16:51:54.387 | INFO     | src.training.train_model:trainloop:164 - Epoch 42 train 0.0329 test 0.5125 metric ['0.8483', '0.8969']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.59it/s]\n",
      "2022-06-28 16:51:58.777 | INFO     | src.training.train_model:trainloop:164 - Epoch 43 train 0.0409 test 0.5489 metric ['0.8373', '0.8900']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.17it/s]\n",
      "2022-06-28 16:52:03.257 | INFO     | src.training.train_model:trainloop:164 - Epoch 44 train 0.0444 test 0.6945 metric ['0.8163', '0.8719']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.05it/s]\n",
      "2022-06-28 16:52:07.820 | INFO     | src.training.train_model:trainloop:164 - Epoch 45 train 0.0581 test 0.8033 metric ['0.7986', '0.8575']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.66it/s]\n",
      "2022-06-28 16:52:12.218 | INFO     | src.training.train_model:trainloop:164 - Epoch 46 train 0.0619 test 0.6178 metric ['0.8481', '0.8856']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.25it/s]\n",
      "2022-06-28 16:52:16.686 | INFO     | src.training.train_model:trainloop:164 - Epoch 47 train 0.0319 test 0.7531 metric ['0.8287', '0.8794']\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.32it/s]\n",
      "2022-06-28 16:52:21.476 | INFO     | src.training.train_model:trainloop:164 - Epoch 48 train 0.0532 test 0.6016 metric ['0.8382', '0.8862']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.84it/s]\n",
      "2022-06-28 16:52:25.802 | INFO     | src.training.train_model:trainloop:164 - Epoch 49 train 0.0383 test 0.6592 metric ['0.8374', '0.8869']\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.95it/s]\n",
      "2022-06-28 16:52:30.128 | INFO     | src.training.train_model:trainloop:164 - Epoch 50 train 0.0196 test 0.6445 metric ['0.8540', '0.8994']\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.21it/s]\n",
      " 64%|██████▍   | 51/80 [04:05<02:19,  4.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb Cell 42'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m train_model\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=2'>3</a>\u001b[0m config \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlen\u001b[39m(v),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhidden_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m128\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m4\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=8'>9</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=11'>12</a>\u001b[0m model \u001b[39m=\u001b[39m train_model\u001b[39m.\u001b[39;49mtrainloop(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=12'>13</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m80\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=13'>14</a>\u001b[0m     model\u001b[39m=\u001b[39;49mrnn\u001b[39m.\u001b[39;49mAttentionNLP(config),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=14'>15</a>\u001b[0m     metrics\u001b[39m=\u001b[39;49mmetrics,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=15'>16</a>\u001b[0m     optimizer\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=16'>17</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=17'>18</a>\u001b[0m     patience \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=18'>19</a>\u001b[0m     factor \u001b[39m=\u001b[39;49m \u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=19'>20</a>\u001b[0m     loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=20'>21</a>\u001b[0m     train_dataloader\u001b[39m=\u001b[39;49mtrainstreamer,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=21'>22</a>\u001b[0m     test_dataloader\u001b[39m=\u001b[39;49mteststreamer,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=22'>23</a>\u001b[0m     log_dir\u001b[39m=\u001b[39;49mlog_dir,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=23'>24</a>\u001b[0m     train_steps\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=24'>25</a>\u001b[0m     eval_steps\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ExamenML/examen-22/notebooks/02_style_detection.ipynb#ch0000039vscode-remote?line=25'>26</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-QTUf-Kx1-py3.9/lib/python3.9/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/code/ExamenML/examen-22/notebooks/../src/training/train_model.py:139\u001b[0m, in \u001b[0;36mtrainloop\u001b[0;34m(epochs, model, optimizer, learning_rate, loss_fn, metrics, train_dataloader, test_dataloader, log_dir, train_steps, eval_steps, patience, factor, tunewriter)\u001b[0m\n\u001b[1;32m    136\u001b[0m     write_gin(log_dir)\n\u001b[1;32m    138\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 139\u001b[0m     train_loss \u001b[39m=\u001b[39m trainbatches(\n\u001b[1;32m    140\u001b[0m         model, train_dataloader, loss_fn, optimizer_, train_steps\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    143\u001b[0m     metric_dict, test_loss \u001b[39m=\u001b[39m evalbatches(\n\u001b[1;32m    144\u001b[0m         model, test_dataloader, loss_fn, metrics, eval_steps\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    147\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n",
      "File \u001b[0;32m~/code/ExamenML/examen-22/notebooks/../src/training/train_model.py:44\u001b[0m, in \u001b[0;36mtrainbatches\u001b[0;34m(model, traindatastreamer, loss_fn, optimizer, train_steps)\u001b[0m\n\u001b[1;32m     42\u001b[0m yhat \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     43\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(yhat, y)\n\u001b[0;32m---> 44\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     45\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     46\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-QTUf-Kx1-py3.9/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-QTUf-Kx1-py3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.2,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=80,\n",
    "    model=rnn.AttentionNLP(config),\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    patience = 3,\n",
    "    factor = 0.9,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=50,\n",
    "    eval_steps=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-QTUf-Kx1-py3.9': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6e807b2bb5ac5eb176c4c6775a07937f8bceddd7fa23b8060fe36db016dbd75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
