{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "from src.models import rnn\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from typing import Callable, Optional\n",
    "from torchtext.vocab import Vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testdataset) //32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419.09375"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset)/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "104+419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 13:11:20.768 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Figure out, for every class, what accuracy you should expect if the model would guess blind on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humor: 0.31414510476474533\n",
      "wiki: 0.31175900380284843\n",
      "proverbs: 0.06196405935426143\n",
      "reuters: 0.3121318320781448\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "dataset = traindataset\n",
    "list_labels = []\n",
    "for i in range(len(dataset)):\n",
    "    label = dataset[i][1]\n",
    "    list_labels.append(label)\n",
    "\n",
    "counter = Counter(list_labels)\n",
    "\n",
    "for i in counter:\n",
    "    accuracy = counter[i]/len(dataset)\n",
    "    print(\"{}: {}\".format(i, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you see. What does this mean? What implications does this have? Why is that good/bad?\n",
    "Are there things down the line that could cause a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What does this mean?\n",
    "\n",
    "There are 4 categories, of which 3 have about the same number of observations, but the 4th one has significantly less observations. Therefore, the traindataset is unbalanced, where the class (proverbs) has less observations.\n",
    "\n",
    "2. What implications does this have?\n",
    "\n",
    "A different metric/loss function is necessary to measure accuracy. Precision/Recall would be good\n",
    "\n",
    "3. Why is this good/bad?\n",
    "\n",
    "The model will have a hard time to learn to classify proverbs, it will be biased towards the majority classes.\n",
    "\n",
    "4. Things that could cause a problem down the line:\n",
    "\n",
    "This dataset is not a balanced one, the category proverbs has significantly less observations available. The amount of observations in this class make up 6% of observations while the others all make up for around 31% of observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    def __init__(self, max: int, vocab: Vocab, clean: Optional[Callable]) -> None:\n",
    "        super().__init__(max, vocab, clean)\n",
    "\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "        return d[label]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4929,  854,   32,   15,  499,   21, 8496,  890]], dtype=torch.int32),\n",
       " tensor([2]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "preprocessor([(x, y)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 36]),\n",
       " tensor([2, 1, 0, 1, 3, 1, 0, 2, 2, 1, 3, 2, 2, 1, 2, 0, 1, 1, 2, 1, 0, 0, 0, 2,\n",
       "         0, 1, 2, 2, 0, 2, 2, 2]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : Metrics, loss\n",
    "Select proper metrics and a loss function.\n",
    "\n",
    "Bonus: implement an additional metric function that is relevant for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "import torch\n",
    "\n",
    "# F1 score metric is good for unbalanced datasets (which we have), this measure combines precision and recall. \n",
    "# Accuracy metric is also loaded to compare with F1 Score\n",
    "metrics = [metrics.F1Score(), metrics.Accuracy()]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : Basemodel\n",
    "Create a base model. It does not need to be naive; you could re-use the\n",
    "NLP models we used for the IMDB.\n",
    "\n",
    "I suggest to start with a hidden size of about 128.\n",
    "Use a config dictionary, or a gin file, both are fine.\n",
    "\n",
    "Bonus points if you create a Trax model in src.models, and even more if you add a trax training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE -> TRAX\n",
    "\n",
    "For the trax implementation, see src.models.rnnTrax\n",
    "For the notebook (inc trainloop) running this model, see the notebook 02_StyleDetectionTrax.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "log_dir = settings.log_dir\n",
    "# TODO between 2 and 8 lines of code, depending on your setup\n",
    "# Assuming you load your model in one line of code from src.models.rnn\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "\n",
    "model = rnn.NLPmodel(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainloop.\n",
    "\n",
    "- Give the lenght of the traindataset, how many batches of 32 can you get out of it?\n",
    "\n",
    "419\n",
    "\n",
    "- If you take a short amount of train_steps (eg 25) for every epoch, how many epochs do you need to cover the complete dataset?\n",
    "\n",
    "There are 103 batches in testset, so 523 in entire dataset.\n",
    "523/25 = 20.92 = 21\n",
    "\n",
    "- What amount of epochs do you need to run the loop with trainsteps=25 to cover the complete traindataset once? \n",
    "\n",
    "419/25 = 16.76 = 17\n",
    "\n",
    "- answer the questions above, and pick a reasonable epoch lenght\n",
    "\n",
    "Picked 20 epochs\n",
    "\n",
    "\n",
    "Start with a default learning_rate of 1e-3 and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 13:13:26.746079: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-26 13:13:26.746110: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-26 13:13:29.811 | INFO     | src.data.data_tools:dir_add_timestamp:66 - Logging to ../tune/20220626-1313\n",
      "100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n",
      "2022-06-26 13:13:35.503 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 1.2901 test 1.2965 metric ['0.1288', '0.3325']\n",
      "100%|██████████| 25/25 [00:04<00:00,  5.37it/s]\n",
      "2022-06-26 13:13:41.061 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 1.2900 test 1.1941 metric ['0.2334', '0.4075']\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.72it/s]\n",
      "2022-06-26 13:13:43.865 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 1.2012 test 1.1335 metric ['0.3256', '0.4713']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.09it/s]\n",
      "2022-06-26 13:13:45.737 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 1.0760 test 0.8992 metric ['0.4380', '0.6012']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.13it/s]\n",
      "2022-06-26 13:13:47.924 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.9344 test 0.8697 metric ['0.3791', '0.5750']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.03it/s]\n",
      "2022-06-26 13:13:49.928 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.9070 test 0.8710 metric ['0.4196', '0.5900']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.24it/s]\n",
      "2022-06-26 13:13:51.991 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.7863 test 0.6963 metric ['0.5825', '0.7188']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.00it/s]\n",
      "2022-06-26 13:13:54.220 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.7358 test 0.5972 metric ['0.6340', '0.7800']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.60it/s]\n",
      "2022-06-26 13:13:56.146 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.5966 test 0.5852 metric ['0.6318', '0.7963']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.14it/s]\n",
      "2022-06-26 13:13:58.040 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.5537 test 0.5576 metric ['0.6285', '0.7875']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.98it/s]\n",
      "2022-06-26 13:14:00.021 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.5495 test 0.4266 metric ['0.6721', '0.8525']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.65it/s]\n",
      "2022-06-26 13:14:02.078 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.5011 test 0.4858 metric ['0.7162', '0.8375']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.80it/s]\n",
      "2022-06-26 13:14:04.342 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.4692 test 0.4437 metric ['0.6559', '0.8313']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.21it/s]\n",
      "2022-06-26 13:14:06.418 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.4798 test 0.4273 metric ['0.7122', '0.8475']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.58it/s]\n",
      "2022-06-26 13:14:08.568 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.4363 test 0.3825 metric ['0.7316', '0.8488']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.84it/s]\n",
      "2022-06-26 13:14:10.536 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.4028 test 0.3818 metric ['0.7607', '0.8625']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.49it/s]\n",
      "2022-06-26 13:14:12.471 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.3734 test 0.4849 metric ['0.7259', '0.8313']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.31it/s]\n",
      "2022-06-26 13:14:14.459 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.3799 test 0.4203 metric ['0.7666', '0.8525']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.74it/s]\n",
      "2022-06-26 13:14:16.484 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.3287 test 0.4872 metric ['0.7591', '0.8250']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.71it/s]\n",
      "2022-06-26 13:14:18.337 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.3381 test 0.3252 metric ['0.8202', '0.8850']\n",
      "100%|██████████| 20/20 [00:48<00:00,  2.43s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=20,\n",
    "    model=model,\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image from the training in tensorboard in the `figures` folder.\n",
    "Explain what you are seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER\n",
    "\n",
    "After 20 epochs, the model is still learning, in both the test and train loss we can see that loss is still decreasing. For further tuning, the amount of epochs should increase. The model is learning more slowly than at the start though, perhaps we can implement step-wise decrease of the learning rate to keep speedy learning at the beginning and change to a lower learning rate once the learning slows down. \n",
    "\n",
    "There are two metrics taken into account, the f1 score and accuracy. We should look mostly at the F1-score as this metric is better adapted to unbalanced datasets. It is visible that accuracy score is indeed significantly higher. F1-score is up to around 75% after 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate the basemodel\n",
    "Create a confusion matrix with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 15.0, 'Predicted'), Text(33.0, 0.5, 'Target')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this in the figures folder.\n",
    "Interpret this. \n",
    "\n",
    "- What is going on?\n",
    "\n",
    "The model performs relatively good for categories 0, 1, and 2, but underperforms significantly for category 3. This is because the model has a bias towards the first 3 categories, as they have many more observations. Most of the wrongly categorized items from category 3 (proverbs) are classified as 2 (wiki).\n",
    "\n",
    "- What is a good metric here?\n",
    "\n",
    "F1 score (precision/recall)\n",
    "\n",
    "- how is your answer to Q1 relevant here?\n",
    "\n",
    "Very, without having the knowledge of the dataset being unbalanced, it wouldn't have been clear why category 3 underperforms so much.\n",
    "\n",
    "- Is there something you could do to fix/improve things, after you see these results?\n",
    "\n",
    "Make the dataset balanced by oversampling the 3rd category or undersampling the first three categories. I would go for oversampling the 3rd (containing less observations) category, because otherwise many observations will be lost. Another way to deal with this is selecting a model (architecture) that deals well with unbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Experiment one - Attention layer\n",
    "\n",
    "Added an attention layer (AttentionNPL in src.models). This is basically the same model as NLPModel but with the addition of an attention layer. In the loss figures, it is visible that this model learns faster than the NLPModel. After 20 epochs, the f1 score of this model is 80% (whereas the base model got to 78% after 20 epochs). \n",
    "\n",
    "2. Experiment two - Add learning rate scheduler\n",
    "\n",
    "Added a learning rate scheduler to the trainloop that starts with LR of 1e-3 and decreases the learning rate with factor of 0.9 if the model doesn't learn for 3 epochs. For this experiment, the number of epochs is also increased, as the model needs more time to plateau. The number of epochs is now set to 100. This model has an f1 score of 86% after 20 epochs. Learning rate has decreased from 1e-3 to 1.35e-4. The negative side of this model is that we see the test loss starting to increase after 60 epochs, this implies overtraining. In order to have less overtraining, we have to make the model a bit more simple, so that the model doesn't completely adapt to the training data. Therefore we now use only 2 GRU layers (instead of 3) with a dropout of 0.2 (instead of 0.1). This seems to work. The model has the same f1 score after 100 epochs, but test loss increases significanly less. \n",
    " \n",
    "\n",
    "FOR FURTHER EXPERIMENTATION - SEE TRAX NOTEBOOK\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 15:17:59.467 | INFO     | src.data.data_tools:dir_add_timestamp:66 - Logging to ../tune/20220625-1517\n",
      "100%|██████████| 25/25 [00:04<00:00,  5.88it/s]\n",
      "2022-06-25 15:18:04.703 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 1.2686 test 1.1356 metric ['0.3617', '0.4675']\n",
      "100%|██████████| 25/25 [00:04<00:00,  6.03it/s]\n",
      "2022-06-25 15:18:09.550 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 1.1025 test 0.9567 metric ['0.3939', '0.5413']\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.06it/s]\n",
      "2022-06-25 15:18:12.281 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 0.9200 test 0.8157 metric ['0.5298', '0.6950']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.71it/s]\n",
      "2022-06-25 15:18:14.481 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 0.7423 test 0.6713 metric ['0.6368', '0.7600']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.80it/s]\n",
      "2022-06-25 15:18:16.631 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.6166 test 0.5576 metric ['0.6804', '0.7900']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.31it/s]\n",
      "2022-06-25 15:18:18.770 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.5495 test 0.5369 metric ['0.7100', '0.7925']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.53it/s]\n",
      "2022-06-25 15:18:20.847 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.5043 test 0.4782 metric ['0.7410', '0.8400']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.42it/s]\n",
      "2022-06-25 15:18:22.937 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.4757 test 0.4085 metric ['0.7957', '0.8662']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.10it/s]\n",
      "2022-06-25 15:18:25.043 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.4492 test 0.4587 metric ['0.7579', '0.8413']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.11it/s]\n",
      "2022-06-25 15:18:27.075 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.4440 test 0.4492 metric ['0.7688', '0.8375']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.75it/s]\n",
      "2022-06-25 15:18:29.257 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.4182 test 0.3998 metric ['0.7684', '0.8625']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.87it/s]\n",
      "2022-06-25 15:18:31.399 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.3617 test 0.3999 metric ['0.8042', '0.8525']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.38it/s]\n",
      "2022-06-25 15:18:33.379 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.3730 test 0.3567 metric ['0.7821', '0.8700']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.72it/s]\n",
      "2022-06-25 15:18:35.527 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.3858 test 0.3873 metric ['0.7649', '0.8612']\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.69it/s]\n",
      "2022-06-25 15:18:37.848 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.3644 test 0.3644 metric ['0.8162', '0.8800']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.60it/s]\n",
      "2022-06-25 15:18:39.920 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.4307 test 0.4050 metric ['0.7638', '0.8575']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.51it/s]\n",
      "2022-06-25 15:18:41.975 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.3027 test 0.3394 metric ['0.8184', '0.8925']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.30it/s]\n",
      "2022-06-25 15:18:44.204 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.3051 test 0.3499 metric ['0.8029', '0.8662']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.25it/s]\n",
      "2022-06-25 15:18:46.432 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.3115 test 0.3279 metric ['0.8311', '0.8875']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.18it/s]\n",
      "2022-06-25 15:18:48.468 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.3172 test 0.3793 metric ['0.7812', '0.8688']\n",
      "100%|██████████| 20/20 [00:48<00:00,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=20,\n",
    "    model=rnn.AttentionNLP(config),\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=100,\n",
    "    model=rnn.AttentionNLP(config),\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    patience = 3,\n",
    "    factor = 0.9,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-QTUf-Kx1-py3.9': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6e807b2bb5ac5eb176c4c6775a07937f8bceddd7fa23b8060fe36db016dbd75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
